# ğŸŒ Anticipation des Besoins en Consommation de BÃ¢timents  

**Projet de modÃ©lisation prÃ©dictive des consommations Ã©nergÃ©tiques et Ã©missions de COâ‚‚ des bÃ¢timents non rÃ©sidentiels de Seattle.**  
Objectif : contribuer Ã  la stratÃ©gie de neutralitÃ© carbone 2050 de la ville.

---

## ğŸ¯ Objectif du projet  
Ce projet sâ€™inscrit dans la dÃ©marche de **neutralitÃ© carbone Ã  lâ€™horizon 2050** portÃ©e par la ville de **Seattle**.  
Lâ€™enjeu est de **prÃ©dire les Ã©missions de COâ‚‚** (`TotalGHGEmissions`) et la **consommation totale dâ€™Ã©nergie** (`SiteEnergyUseWN(kBtu)`) des bÃ¢timents non rÃ©sidentiels, Ã  partir des donnÃ©es structurelles disponibles dans la base **Building Energy Benchmarking 2016**.

---

## ğŸ§© Contenu du projet  

Le dÃ©pÃ´t contient :  
- **Trois notebooks Jupyter** :  
  1. **Analyse exploratoire & Feature Engineering**  
     - Nettoyage du dataset (46 colonnes â†’ 18 pertinentes)  
     - SÃ©lection des bÃ¢timents non rÃ©sidentiels (`BuildingType`)  
     - CrÃ©ation de nouvelles variables (`Electricity(%)`, `NaturalGas(%)`, `SteamUse(%)`, `Age`)  
     - DÃ©tection et traitement des valeurs aberrantes  
  2. **ModÃ©lisation de la variable TotalGHGEmissions**  
     - Comparaison de modÃ¨les : Linear, Lasso, Ridge, Random Forest, Gradient Boosting, SVM  
     - Meilleur modÃ¨le : **Gradient Boosting Regression**  
       - RÂ² = 0.60  
       - MAE = 86.54  
       - RMSE = 216.81  
  3. **ModÃ©lisation de la variable SiteEnergyUseWN(kBtu)**  
     - Meilleur modÃ¨le : **Gradient Boosting Regression**  
       - RÂ² = 0.71  
       - MAE = 3.86Ã—10â¶  
       - RMSE = 7.22Ã—10â¶  
- **PrÃ©sentation PowerPoint** : synthÃ¨se visuelle des rÃ©sultats et analyses de la *feature importance* (globale & locale).

---

## ğŸ” MÃ©thodologie  

1. **PrÃ©paration et nettoyage des donnÃ©es**  
   - Filtrage des bÃ¢timents non rÃ©sidentiels  
   - Suppression des valeurs non conformes ou par dÃ©faut  
   - VÃ©rification mÃ©tier :  
     `PropertyGFATotal = PropertyGFABuilding(s) + PropertyGFAParking`  

2. **Feature Engineering**  
   - CrÃ©ation de variables dÃ©rivÃ©es et ratios Ã©nergÃ©tiques  
   - Transformation pour Ã©viter le *data leakage*  
   - Normalisation des valeurs  

3. **ModÃ©lisation**  
   - Comparaison de plusieurs algorithmes :  
     Linear, Lasso, Ridge, Random Forest, Gradient Boosting, Bagging, SVM  
   - Validation croisÃ©e (KFold)  
   - SÃ©lection finale du **Gradient Boosting Regression**

4. **Analyse post-modÃ©lisation**  
   - *Feature importance* globale et locale  
   - Ã‰tude de lâ€™influence du `ENERGYSTARScore` sur les performances :  
     - Impact modÃ©rÃ© mais positif sur la prÃ©cision des prÃ©dictions.

---

## ğŸ“Š RÃ©sultats synthÃ©tiques  

| Variable cible | Meilleur modÃ¨le | RÂ² | MAE | RMSE |
|----------------|----------------|----|-----|------|
| `TotalGHGEmissions` | Gradient Boosting Regression | 0.60 | 86.54 | 216.81 |
| `SiteEnergyUseWN(kBtu)` | Gradient Boosting Regression | 0.71 | 3.86Ã—10â¶ | 7.22Ã—10â¶ |

---

## ğŸ› ï¸ Technologies utilisÃ©es  

- **Python** : Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn  
- **ModÃ¨les** : Linear, Ridge, Lasso, RandomForest, GradientBoosting, SVM  
- **Validation** : GridSearchCV, KFold, MAE/RMSE  
- **Visualisation** : Feature Importance, Boxplots, Heatmaps  

---

## ğŸ“‚ Structure du dÃ©pÃ´t  

```text
anticipation_besoins_consommation
â”‚
â”œâ”€â”€ Notebook_1_Exploration_Feature_Engineering.ipynb
â”œâ”€â”€ Notebook_2_Modelisation_TotalGHGEmissions.ipynb
â”œâ”€â”€ Notebook_3_Modelisation_SiteEnergyUseWN.ipynb
â”œâ”€â”€ Martineau_Alexandre_4_presentation_05204.pdf
â””â”€â”€ README.md
```
